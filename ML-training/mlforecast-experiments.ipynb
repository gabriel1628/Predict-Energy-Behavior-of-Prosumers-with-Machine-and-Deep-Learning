{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2ac34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fc7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>96.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>17.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>656.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>59.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>501.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds        y\n",
       "0          0 2021-09-01   96.590\n",
       "1          1 2021-09-01   17.314\n",
       "2          2 2021-09-01  656.859\n",
       "3          3 2021-09-01   59.000\n",
       "4          4 2021-09-01  501.760"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/consumption.csv\", usecols=[\"prediction_unit_id\", \"datetime\", \"target\"]\n",
    ")[[\"prediction_unit_id\", \"datetime\", \"target\"]].rename(\n",
    "    columns={\"prediction_unit_id\": \"unique_id\", \"datetime\": \"ds\", \"target\": \"y\"}\n",
    ")\n",
    "df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e1196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id    0\n",
       "ds           0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"] = df[\"y\"].ffill()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788804bd",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a32c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3312, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906150</th>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-28 00:00:00</td>\n",
       "      <td>5.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906217</th>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-28 01:00:00</td>\n",
       "      <td>4.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906284</th>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-28 02:00:00</td>\n",
       "      <td>4.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906351</th>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-28 03:00:00</td>\n",
       "      <td>4.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906418</th>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-28 04:00:00</td>\n",
       "      <td>4.518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        unique_id                  ds      y\n",
       "906150         26 2023-03-28 00:00:00  5.137\n",
       "906217         26 2023-03-28 01:00:00  4.212\n",
       "906284         26 2023-03-28 02:00:00  4.917\n",
       "906351         26 2023-03-28 03:00:00  4.195\n",
       "906418         26 2023-03-28 04:00:00  4.518"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking the last 48 hours for test\n",
    "horizon = 48\n",
    "for i in df[\"unique_id\"].unique():\n",
    "    if i == df[\"unique_id\"].unique()[0]:\n",
    "        df_test = df[df[\"unique_id\"]==i][-horizon:]\n",
    "        continue\n",
    "    df_test = pd.concat([df_test, df[df[\"unique_id\"]==i][-horizon:]])\n",
    "    \n",
    "df_test.sort_index(inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5c8fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>96.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>17.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>656.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>59.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>501.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds        y\n",
       "0          0 2021-09-01   96.590\n",
       "1          1 2021-09-01   17.314\n",
       "2          2 2021-09-01  656.859\n",
       "3          3 2021-09-01   59.000\n",
       "4          4 2021-09-01  501.760"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = [idx for idx in df.index if idx not in df_test.index]\n",
    "df_train = df.loc[train_idx]\n",
    "df_train.shape\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a8ad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] == df_train.shape[0] + df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a86675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1] == df_train.shape[1] == df_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89823d",
   "metadata": {
    "papermill": {
     "duration": 0.022551,
     "end_time": "2024-03-27T14:25:01.037231",
     "exception": false,
     "start_time": "2024-03-27T14:25:01.014680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f3923d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:25:01.150546Z",
     "iopub.status.busy": "2024-03-27T14:25:01.149906Z",
     "iopub.status.idle": "2024-03-27T14:25:03.037626Z",
     "shell.execute_reply": "2024-03-27T14:25:03.036087Z"
    },
    "papermill": {
     "duration": 1.978328,
     "end_time": "2024-03-27T14:25:03.040362",
     "exception": false,
     "start_time": "2024-03-27T14:25:01.062034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.target_transforms import Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2a0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_params = dict(id_col=\"building_id\", time_col=\"datetime\", target_col=\"consumption\")\n",
    "# col_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b829341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>...</th>\n",
       "      <th>lag44</th>\n",
       "      <th>lag45</th>\n",
       "      <th>lag46</th>\n",
       "      <th>lag47</th>\n",
       "      <th>lag48</th>\n",
       "      <th>expanding_mean_lag1</th>\n",
       "      <th>rolling_mean_lag24_window_size48</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-04 23:00:00</td>\n",
       "      <td>-6.630</td>\n",
       "      <td>10.176</td>\n",
       "      <td>-16.948</td>\n",
       "      <td>30.391</td>\n",
       "      <td>7.926</td>\n",
       "      <td>-17.201</td>\n",
       "      <td>-3.185</td>\n",
       "      <td>6.491</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.897</td>\n",
       "      <td>-8.661</td>\n",
       "      <td>-15.113</td>\n",
       "      <td>-2.237</td>\n",
       "      <td>-6.991</td>\n",
       "      <td>4.519704</td>\n",
       "      <td>5.480750</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-04 23:00:00</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>4.648</td>\n",
       "      <td>5.220</td>\n",
       "      <td>-13.346</td>\n",
       "      <td>-10.982</td>\n",
       "      <td>-2.404</td>\n",
       "      <td>-1.357</td>\n",
       "      <td>1.997</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>-2.184</td>\n",
       "      <td>2.200</td>\n",
       "      <td>-1.378</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>0.645268</td>\n",
       "      <td>0.864937</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-04 23:00:00</td>\n",
       "      <td>-35.639</td>\n",
       "      <td>-62.993</td>\n",
       "      <td>5.519</td>\n",
       "      <td>17.114</td>\n",
       "      <td>47.251</td>\n",
       "      <td>-16.126</td>\n",
       "      <td>-23.379</td>\n",
       "      <td>32.545</td>\n",
       "      <td>...</td>\n",
       "      <td>-102.505</td>\n",
       "      <td>-68.646</td>\n",
       "      <td>-42.397</td>\n",
       "      <td>-44.788</td>\n",
       "      <td>-21.684</td>\n",
       "      <td>33.502592</td>\n",
       "      <td>38.503042</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-04 23:00:00</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-4.200</td>\n",
       "      <td>-3.600</td>\n",
       "      <td>-4.900</td>\n",
       "      <td>-17.900</td>\n",
       "      <td>-16.500</td>\n",
       "      <td>-38.600</td>\n",
       "      <td>-10.800</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.700</td>\n",
       "      <td>-17.200</td>\n",
       "      <td>-19.300</td>\n",
       "      <td>-11.700</td>\n",
       "      <td>-5.500</td>\n",
       "      <td>-7.554930</td>\n",
       "      <td>4.497917</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-04 23:00:00</td>\n",
       "      <td>-68.429</td>\n",
       "      <td>-83.631</td>\n",
       "      <td>-70.391</td>\n",
       "      <td>-16.480</td>\n",
       "      <td>-11.291</td>\n",
       "      <td>-59.362</td>\n",
       "      <td>-127.090</td>\n",
       "      <td>-178.232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-46.453</td>\n",
       "      <td>-51.881</td>\n",
       "      <td>27.731</td>\n",
       "      <td>-9.685</td>\n",
       "      <td>-38.533958</td>\n",
       "      <td>21.538812</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds       y    lag1    lag2    lag3    lag4  \\\n",
       "5795          0 2021-09-04 23:00:00  -6.630  10.176 -16.948  30.391   7.926   \n",
       "5796          1 2021-09-04 23:00:00  -0.656   4.648   5.220 -13.346 -10.982   \n",
       "5797          2 2021-09-04 23:00:00 -35.639 -62.993   5.519  17.114  47.251   \n",
       "5798          3 2021-09-04 23:00:00  -1.100  -4.200  -3.600  -4.900 -17.900   \n",
       "5799          4 2021-09-04 23:00:00 -68.429 -83.631 -70.391 -16.480 -11.291   \n",
       "\n",
       "        lag5     lag6     lag7  ...    lag44   lag45   lag46   lag47   lag48  \\\n",
       "5795 -17.201   -3.185    6.491  ...   -8.897  -8.661 -15.113  -2.237  -6.991   \n",
       "5796  -2.404   -1.357    1.997  ...   -1.600  -2.184   2.200  -1.378  -0.827   \n",
       "5797 -16.126  -23.379   32.545  ... -102.505 -68.646 -42.397 -44.788 -21.684   \n",
       "5798 -16.500  -38.600  -10.800  ...  -18.700 -17.200 -19.300 -11.700  -5.500   \n",
       "5799 -59.362 -127.090 -178.232  ...   -0.884 -46.453 -51.881  27.731  -9.685   \n",
       "\n",
       "      expanding_mean_lag1  rolling_mean_lag24_window_size48  month  dayofweek  \\\n",
       "5795             4.519704                          5.480750      9          5   \n",
       "5796             0.645268                          0.864937      9          5   \n",
       "5797            33.502592                         38.503042      9          5   \n",
       "5798            -7.554930                          4.497917      9          5   \n",
       "5799           -38.533958                         21.538812      9          5   \n",
       "\n",
       "      hour  \n",
       "5795    23  \n",
       "5796    23  \n",
       "5797    23  \n",
       "5798    23  \n",
       "5799    23  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb_params = {\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 512,\n",
    "}\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models={\n",
    "        'lgb': LGBMRegressor(**lgb_params),\n",
    "        # 'q75': LGBMRegressor(**lgb_params, objective='quantile', alpha=0.75),\n",
    "        # 'q25': LGBMRegressor(**lgb_params, objective='quantile', alpha=0.25),\n",
    "    },\n",
    "    freq=\"h\",\n",
    "    target_transforms=[Differences([24])],\n",
    "    lags=[i+1 for i in range(48)],\n",
    "    lag_transforms={\n",
    "        1: [ExpandingMean()],\n",
    "        24: [RollingMean(window_size=48)],\n",
    "    },\n",
    "    date_features=[\"month\", \"dayofweek\", \"hour\"],\n",
    ")\n",
    "\n",
    "# fcst.preprocess(df_train, **col_params).head()\n",
    "fcst.preprocess(df_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234d3d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.213608741760254"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# fcst.fit(df_train, **col_params)\n",
    "fcst.fit(df_train)\n",
    "end = time.time()\n",
    "t = end - start\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e4f6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf58712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mape, mase, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915882a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_test, fcst.predict(horizon), on=[\"unique_id\", \"ds\"])\n",
    "daily_mase = partial(mase, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70c5f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>43.295707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.609863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>0.636145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>61.929235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb\n",
       "metric           \n",
       "mae     43.295707\n",
       "mape     0.609863\n",
       "mase     0.636145\n",
       "rmse    61.929235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_ref = evaluate(\n",
    "    df_eval, metrics=[mape, daily_mase, mae, rmse], train_df=df_train#, **col_params\n",
    ")\n",
    "error_ref.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a55a5f",
   "metadata": {},
   "source": [
    "# Error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fecc5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36534479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = error_ref[\"metric\"] == \"mape\"\n",
    "sns.boxplot(x=error_ref.loc[mask, \"lgb\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a08350b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=error_ref.loc[mask, \"lgb\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85d789",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f72f82",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90d60802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>...</th>\n",
       "      <th>lag43</th>\n",
       "      <th>lag44</th>\n",
       "      <th>lag45</th>\n",
       "      <th>lag46</th>\n",
       "      <th>lag47</th>\n",
       "      <th>rolling_mean_lag1_window_size24</th>\n",
       "      <th>rolling_mean_lag24_window_size24</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-02 23:00:00</td>\n",
       "      <td>120.54</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.13</td>\n",
       "      <td>121.033</td>\n",
       "      <td>80.621</td>\n",
       "      <td>43.428</td>\n",
       "      <td>...</td>\n",
       "      <td>88.184</td>\n",
       "      <td>87.955</td>\n",
       "      <td>91.594</td>\n",
       "      <td>77.691</td>\n",
       "      <td>96.59</td>\n",
       "      <td>87.588333</td>\n",
       "      <td>79.96975</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds       y     lag1     lag2     lag3  \\\n",
       "2867          0 2021-09-02 23:00:00  120.54  134.986  150.412  152.763   \n",
       "\n",
       "        lag4     lag5    lag6    lag7  ...   lag43   lag44   lag45   lag46  \\\n",
       "2867  136.13  121.033  80.621  43.428  ...  88.184  87.955  91.594  77.691   \n",
       "\n",
       "      lag47  rolling_mean_lag1_window_size24  \\\n",
       "2867  96.59                        87.588333   \n",
       "\n",
       "      rolling_mean_lag24_window_size24  month  dayofweek  hour  \n",
       "2867                          79.96975      9          3    23  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=\"h\",\n",
    "    # target_transforms=[Differences([24])],\n",
    "    lags=[i+1 for i in range(47)],\n",
    "    lag_transforms={\n",
    "        1: [ExpandingMean()],\n",
    "        1: [RollingMean(window_size=24)],\n",
    "        24: [RollingMean(window_size=24)],\n",
    "        # 24: [RollingMean(window_size=48)],\n",
    "    },\n",
    "    date_features=[\"month\", \"dayofweek\", \"hour\"],\n",
    ")\n",
    "\n",
    "fcst.preprocess(df_train).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eea8c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcst.preprocess(df_train.groupby(\"unique_id\").head(48)).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74a21e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fcst.preprocess(df_train).rename(columns={\"y\": \"lag0\"})\n",
    "# X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be0688a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000965, 55), (1000965,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X_train.align(\n",
    "    df_train.groupby(\"unique_id\")[\"y\"].shift(-24).rename(\"lead24\").dropna(),\n",
    "    axis=0,\n",
    "    join=\"inner\"\n",
    ")\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205c3b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.01 , 0.1  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.logspace(-3, -1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "316a784f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.08333333333333333, 0.0, -1.2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import uniform, loguniform, randint\n",
    "uniform\n",
    "mean, var, skew, kurt = uniform.stats(moments='mvsk')\n",
    "mean, var, skew, kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6d721b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-5, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa26d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12fdb341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2560186404424365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2560186404424365\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2428668179219408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2428668179219408\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.31233911067827613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.31233911067827613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5319450186421157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5319450186421157\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5560699842170359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5560699842170359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6924145688620424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6924145688620424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.16505159298527952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.16505159298527952\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.330893825622149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.330893825622149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12788\n",
      "[LightGBM] [Info] Number of data points in the train set: 250242, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 463.730390\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12793\n",
      "[LightGBM] [Info] Number of data points in the train set: 500483, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 419.094628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 750724, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 435.326129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.1343885211152184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1343885211152184\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47454011884736247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47454011884736247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12794\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000965, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 461.567394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=LGBMRegressor(),\n",
       "                   param_distributions={&#x27;feature_fraction&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827E650&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C98256A90&gt;,\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C97C6B690&gt;,\n",
       "                                        &#x27;num_leaves&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C9827C210&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827F7D0&gt;},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=LGBMRegressor(),\n",
       "                   param_distributions={&#x27;feature_fraction&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827E650&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C98256A90&gt;,\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C97C6B690&gt;,\n",
       "                                        &#x27;num_leaves&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C9827C210&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827F7D0&gt;},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=LGBMRegressor(),\n",
       "                   param_distributions={'feature_fraction': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827E650>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C98256A90>,\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C97C6B690>,\n",
       "                                        'num_leaves': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C9827C210>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000027C9827F7D0>},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "\n",
    "# param_dist = {\n",
    "#     \"learning_rate\": np.logspace(-4, -1),\n",
    "#     \"max_depth\": np.random.randint(1, 20),\n",
    "#     \"num_leaves\": np.random.randint(10, 200),\n",
    "#     \"feature_fraction\": np.linspace(0.1, 1.0, 9),\n",
    "#     \"subsample\": np.linspace(0.1, 1.0, 9)\n",
    "# }\n",
    "param_dist = {\n",
    "    \"learning_rate\": loguniform(0.0001, 0.1),\n",
    "    \"max_depth\": randint(1, 20),\n",
    "    \"num_leaves\": randint(10, 200),\n",
    "    \"feature_fraction\": uniform(0.1, 1.0),\n",
    "    \"subsample\": uniform(0.1, 1.0)\n",
    "}\n",
    "\n",
    "lgb = LGBMRegressor()\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "random_search = RandomizedSearchCV(\n",
    "    lgb, param_distributions=param_dist, scoring=\"neg_mean_absolute_error\",\n",
    "    # n_jobs=-1,\n",
    "    cv=tscv, verbose=1,\n",
    "    random_state=42, n_iter=10\n",
    ")\n",
    "random_search.fit(X_train.drop(columns=[\"unique_id\", \"ds\"]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb831f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_feature_fraction</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.518587</td>\n",
       "      <td>1.114614</td>\n",
       "      <td>0.455290</td>\n",
       "      <td>0.060238</td>\n",
       "      <td>0.47454</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>0.698658</td>\n",
       "      <td>{'feature_fraction': 0.47454011884736247, 'lea...</td>\n",
       "      <td>-68.751935</td>\n",
       "      <td>-63.640847</td>\n",
       "      <td>-75.399803</td>\n",
       "      <td>-69.264195</td>\n",
       "      <td>4.814220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.166924</td>\n",
       "      <td>1.242418</td>\n",
       "      <td>0.566787</td>\n",
       "      <td>0.034711</td>\n",
       "      <td>0.256019</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>11</td>\n",
       "      <td>97</td>\n",
       "      <td>0.433709</td>\n",
       "      <td>{'feature_fraction': 0.2560186404424365, 'lear...</td>\n",
       "      <td>-499.978442</td>\n",
       "      <td>-509.859418</td>\n",
       "      <td>-542.526340</td>\n",
       "      <td>-517.454733</td>\n",
       "      <td>18.181447</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.046783</td>\n",
       "      <td>1.270952</td>\n",
       "      <td>0.297952</td>\n",
       "      <td>0.043957</td>\n",
       "      <td>0.242867</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>0.932443</td>\n",
       "      <td>{'feature_fraction': 0.2428668179219408, 'lear...</td>\n",
       "      <td>-257.238850</td>\n",
       "      <td>-261.488442</td>\n",
       "      <td>-275.987441</td>\n",
       "      <td>-264.904911</td>\n",
       "      <td>8.026274</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.485729</td>\n",
       "      <td>0.795963</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>0.312339</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>{'feature_fraction': 0.31233911067827613, 'lea...</td>\n",
       "      <td>-504.754588</td>\n",
       "      <td>-515.448099</td>\n",
       "      <td>-548.736894</td>\n",
       "      <td>-522.979860</td>\n",
       "      <td>18.728880</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.903458</td>\n",
       "      <td>2.736335</td>\n",
       "      <td>0.619311</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>0.531945</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>10</td>\n",
       "      <td>197</td>\n",
       "      <td>0.466362</td>\n",
       "      <td>{'feature_fraction': 0.5319450186421157, 'lear...</td>\n",
       "      <td>-478.187126</td>\n",
       "      <td>-488.400651</td>\n",
       "      <td>-519.439958</td>\n",
       "      <td>-495.342578</td>\n",
       "      <td>17.542174</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.518587      1.114614         0.455290        0.060238   \n",
       "1       4.166924      1.242418         0.566787        0.034711   \n",
       "2       3.046783      1.270952         0.297952        0.043957   \n",
       "3       2.485729      0.795963         0.271532        0.041740   \n",
       "4       6.903458      2.736335         0.619311        0.015245   \n",
       "\n",
       "  param_feature_fraction param_learning_rate param_max_depth param_num_leaves  \\\n",
       "0                0.47454            0.071145              11               81   \n",
       "1               0.256019            0.000294              11               97   \n",
       "2               0.242867            0.008967               2               97   \n",
       "3               0.312339            0.000351               1               67   \n",
       "4               0.531945            0.000748              10              197   \n",
       "\n",
       "  param_subsample                                             params  \\\n",
       "0        0.698658  {'feature_fraction': 0.47454011884736247, 'lea...   \n",
       "1        0.433709  {'feature_fraction': 0.2560186404424365, 'lear...   \n",
       "2        0.932443  {'feature_fraction': 0.2428668179219408, 'lear...   \n",
       "3        0.624756  {'feature_fraction': 0.31233911067827613, 'lea...   \n",
       "4        0.466362  {'feature_fraction': 0.5319450186421157, 'lear...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0         -68.751935         -63.640847         -75.399803       -69.264195   \n",
       "1        -499.978442        -509.859418        -542.526340      -517.454733   \n",
       "2        -257.238850        -261.488442        -275.987441      -264.904911   \n",
       "3        -504.754588        -515.448099        -548.736894      -522.979860   \n",
       "4        -478.187126        -488.400651        -519.439958      -495.342578   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        4.814220                1  \n",
       "1       18.181447                8  \n",
       "2        8.026274                5  \n",
       "3       18.728880                9  \n",
       "4       17.542174                6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3aa25",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c3798",
   "metadata": {},
   "source": [
    "### Default optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8638adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabriel.chehade\\Documents\\Projets\\Github\\Predict-Energy-Behavior-of-Prosumers-with-Machine-and-Deep-Learning\\ML-training\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "from mlforecast.auto import (\n",
    "    AutoLightGBM,\n",
    "    AutoMLForecast,\n",
    "    AutoModel,\n",
    "    AutoRidge,\n",
    "    ridge_space,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0c23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "auto_mlf = AutoMLForecast(\n",
    "    models={'lgb': AutoLightGBM(), 'ridge': AutoRidge()},\n",
    "    freq=\"h\",\n",
    "    season_length=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db17232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 10s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoMLForecast(models={'lgb': AutoModel(model=LGBMRegressor), 'ridge': AutoModel(model=Ridge)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "auto_mlf.fit(\n",
    "    df_train,\n",
    "    n_windows=2,\n",
    "    h=horizon,\n",
    "    num_samples=2,  # number of trials to run\n",
    "    # **col_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a11bd2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>lgb</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 00:00:00</td>\n",
       "      <td>565.454859</td>\n",
       "      <td>473.285688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 01:00:00</td>\n",
       "      <td>563.887968</td>\n",
       "      <td>435.791833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>548.292567</td>\n",
       "      <td>420.404486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 03:00:00</td>\n",
       "      <td>538.535335</td>\n",
       "      <td>425.605559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 04:00:00</td>\n",
       "      <td>519.713864</td>\n",
       "      <td>404.789790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 19:00:00</td>\n",
       "      <td>7.687514</td>\n",
       "      <td>1.378594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 20:00:00</td>\n",
       "      <td>5.374252</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 21:00:00</td>\n",
       "      <td>6.561874</td>\n",
       "      <td>7.424761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 22:00:00</td>\n",
       "      <td>9.323739</td>\n",
       "      <td>10.326647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>10.444055</td>\n",
       "      <td>10.832715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds         lgb       ridge\n",
       "0             0 2023-05-30 00:00:00  565.454859  473.285688\n",
       "1             0 2023-05-30 01:00:00  563.887968  435.791833\n",
       "2             0 2023-05-30 02:00:00  548.292567  420.404486\n",
       "3             0 2023-05-30 03:00:00  538.535335  425.605559\n",
       "4             0 2023-05-30 04:00:00  519.713864  404.789790\n",
       "...         ...                 ...         ...         ...\n",
       "3307         68 2023-05-31 19:00:00    7.687514    1.378594\n",
       "3308         68 2023-05-31 20:00:00    5.374252    2.770000\n",
       "3309         68 2023-05-31 21:00:00    6.561874    7.424761\n",
       "3310         68 2023-05-31 22:00:00    9.323739   10.326647\n",
       "3311         68 2023-05-31 23:00:00   10.444055   10.832715\n",
       "\n",
       "[3312 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = auto_mlf.predict(horizon)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54469f50",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d447e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_test, preds, on=[\"unique_id\", \"ds\"])\n",
    "daily_mase = partial(mase, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dad5b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>110.089964</td>\n",
       "      <td>49.134963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>1.349701</td>\n",
       "      <td>0.513245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>1.212543</td>\n",
       "      <td>0.752745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>143.436201</td>\n",
       "      <td>66.745755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lgb      ridge\n",
       "metric                       \n",
       "mae     110.089964  49.134963\n",
       "mape      1.349701   0.513245\n",
       "mase      1.212543   0.752745\n",
       "rmse    143.436201  66.745755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = evaluate(\n",
    "    df_eval, metrics=[mape, daily_mase, mae, rmse], train_df=df_train\n",
    ")\n",
    "error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f7213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.79425672,  5.839256  ],\n",
       "       [ 0.73983844, -0.09661743],\n",
       "       [ 0.57639779,  0.11660029],\n",
       "       [81.50696623,  4.81652011]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values\n",
    " - error_ref.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e0a21",
   "metadata": {},
   "source": [
    "### Tuning lgbm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546ed06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lgb_config(trial: optuna.Trial):\n",
    "    return {\n",
    "        'learning_rate': 0.05,\n",
    "        'verbosity': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512, log=True),\n",
    "        'objective': trial.suggest_categorical('objective', ['l1', 'l2', 'mape']),\n",
    "    }\n",
    "\n",
    "my_lgb = AutoModel(\n",
    "    model=LGBMRegressor(),\n",
    "    config=my_lgb_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5080454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 55s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auto_mlf = AutoMLForecast(\n",
    "    models={'my_lgb': my_lgb},\n",
    "    freq=\"h\",\n",
    "    season_length=24,\n",
    ").fit(\n",
    "    df_train,\n",
    "    n_windows=2,\n",
    "    h=horizon,\n",
    "    num_samples=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a76c5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>my_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 00:00:00</td>\n",
       "      <td>479.413661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 01:00:00</td>\n",
       "      <td>442.694981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>436.263568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 03:00:00</td>\n",
       "      <td>433.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 04:00:00</td>\n",
       "      <td>415.045998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 19:00:00</td>\n",
       "      <td>2.817724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 20:00:00</td>\n",
       "      <td>3.457108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 21:00:00</td>\n",
       "      <td>4.030305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 22:00:00</td>\n",
       "      <td>4.219662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>4.167689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds      my_lgb\n",
       "0             0 2023-05-30 00:00:00  479.413661\n",
       "1             0 2023-05-30 01:00:00  442.694981\n",
       "2             0 2023-05-30 02:00:00  436.263568\n",
       "3             0 2023-05-30 03:00:00  433.239130\n",
       "4             0 2023-05-30 04:00:00  415.045998\n",
       "...         ...                 ...         ...\n",
       "3307         68 2023-05-31 19:00:00    2.817724\n",
       "3308         68 2023-05-31 20:00:00    3.457108\n",
       "3309         68 2023-05-31 21:00:00    4.030305\n",
       "3310         68 2023-05-31 22:00:00    4.219662\n",
       "3311         68 2023-05-31 23:00:00    4.167689\n",
       "\n",
       "[3312 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = auto_mlf.predict(horizon)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527d16c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f93e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_test, preds, on=[\"unique_id\", \"ds\"])\n",
    "daily_mase = partial(mase, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21eb0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_lgb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>62.363251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.824423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>1.004024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>79.556004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           my_lgb\n",
       "metric           \n",
       "mae     62.363251\n",
       "mape     0.824423\n",
       "mase     1.004024\n",
       "rmse    79.556004"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = evaluate(\n",
    "    df_eval, metrics=[mape, daily_mase, mae, rmse], train_df=df_train\n",
    ")\n",
    "error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36841140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.06754412],\n",
       "       [ 0.21456032],\n",
       "       [ 0.36787877],\n",
       "       [17.62676925]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values\n",
    " - error_ref.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d974477",
   "metadata": {},
   "source": [
    "### Tuning ridge parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76b06493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        [('encoder', OneHotEncoder(), ['unique_id'])],\n",
    "        remainder='passthrough',\n",
    "    ),\n",
    "    Ridge()\n",
    ")\n",
    "my_auto_ridge = AutoModel(\n",
    "    ridge_pipeline,\n",
    "    # the space must have the name of the estimator followed by the parameter\n",
    "    # you could also tune the encoder here\n",
    "    lambda trial: {f'ridge__{k}': v for k, v in ridge_space(trial).items()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "926ced80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.27 s\n",
      "Wall time: 8.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auto_mlf = AutoMLForecast(\n",
    "    models={'ridge': my_auto_ridge},\n",
    "    freq=\"h\",\n",
    "    season_length=24,\n",
    "    fit_config=lambda trial: {'static_features': ['unique_id']}\n",
    ").fit(\n",
    "    df_train,\n",
    "    n_windows=2,\n",
    "    h=horizon,\n",
    "    num_samples=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd2dae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 00:00:00</td>\n",
       "      <td>464.089417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 01:00:00</td>\n",
       "      <td>419.716974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>401.566783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 03:00:00</td>\n",
       "      <td>409.073716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 04:00:00</td>\n",
       "      <td>385.492595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 19:00:00</td>\n",
       "      <td>2.227154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 20:00:00</td>\n",
       "      <td>3.431440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 21:00:00</td>\n",
       "      <td>8.573857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 22:00:00</td>\n",
       "      <td>12.121622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>12.798349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds       ridge\n",
       "0             0 2023-05-30 00:00:00  464.089417\n",
       "1             0 2023-05-30 01:00:00  419.716974\n",
       "2             0 2023-05-30 02:00:00  401.566783\n",
       "3             0 2023-05-30 03:00:00  409.073716\n",
       "4             0 2023-05-30 04:00:00  385.492595\n",
       "...         ...                 ...         ...\n",
       "3307         68 2023-05-31 19:00:00    2.227154\n",
       "3308         68 2023-05-31 20:00:00    3.431440\n",
       "3309         68 2023-05-31 21:00:00    8.573857\n",
       "3310         68 2023-05-31 22:00:00   12.121622\n",
       "3311         68 2023-05-31 23:00:00   12.798349\n",
       "\n",
       "[3312 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = auto_mlf.predict(horizon)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606de35",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3216ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_test, preds, on=[\"unique_id\", \"ds\"])\n",
    "daily_mase = partial(mase, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fd18daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>45.261171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.891970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>0.738090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>60.205129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ridge\n",
       "metric           \n",
       "mae     45.261171\n",
       "mape     0.891970\n",
       "mase     0.738090\n",
       "rmse    60.205129"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = evaluate(\n",
    "    df_eval, metrics=[mape, daily_mase, mae, rmse], train_df=df_train\n",
    ")\n",
    "error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96c3e7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.96546458],\n",
       "       [ 0.28210752],\n",
       "       [ 0.10194502],\n",
       "       [-1.72410544]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values\n",
    " - error_ref.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92cc53b",
   "metadata": {},
   "source": [
    "### Tuning features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "001c959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.lag_transforms import ExponentiallyWeightedMean, RollingMean\n",
    "\n",
    "def my_init_config(trial: optuna.Trial):\n",
    "    lag_transforms = [\n",
    "        ExponentiallyWeightedMean(alpha=0.3),\n",
    "        RollingMean(window_size=24 * 7, min_samples=1),\n",
    "    ]\n",
    "    lag_to_transform = trial.suggest_categorical('lag_to_transform', [24, 48])\n",
    "    return {\n",
    "        'lags': [24 * i for i in range(1, 7)],  # this won't be tuned\n",
    "        'lag_transforms': {lag_to_transform: lag_transforms},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d50f41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.75 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auto_mlf = AutoMLForecast(\n",
    "    # models={'ridge': my_auto_ridge},\n",
    "    # fit_config=lambda trial: {'static_features': ['unique_id']}\n",
    "    models=[AutoRidge()],\n",
    "    freq=\"h\",\n",
    "    season_length=24,\n",
    "    init_config=my_init_config,\n",
    ").fit(\n",
    "    df_train,\n",
    "    n_windows=2,\n",
    "    h=horizon,\n",
    "    num_samples=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "165a7646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 00:00:00</td>\n",
       "      <td>431.601917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 01:00:00</td>\n",
       "      <td>381.425067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>376.351815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 03:00:00</td>\n",
       "      <td>382.440528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-30 04:00:00</td>\n",
       "      <td>359.983041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 19:00:00</td>\n",
       "      <td>1.329570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 20:00:00</td>\n",
       "      <td>2.455559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 21:00:00</td>\n",
       "      <td>6.480433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 22:00:00</td>\n",
       "      <td>9.512457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>68</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>9.996963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds   AutoRidge\n",
       "0             0 2023-05-30 00:00:00  431.601917\n",
       "1             0 2023-05-30 01:00:00  381.425067\n",
       "2             0 2023-05-30 02:00:00  376.351815\n",
       "3             0 2023-05-30 03:00:00  382.440528\n",
       "4             0 2023-05-30 04:00:00  359.983041\n",
       "...         ...                 ...         ...\n",
       "3307         68 2023-05-31 19:00:00    1.329570\n",
       "3308         68 2023-05-31 20:00:00    2.455559\n",
       "3309         68 2023-05-31 21:00:00    6.480433\n",
       "3310         68 2023-05-31 22:00:00    9.512457\n",
       "3311         68 2023-05-31 23:00:00    9.996963\n",
       "\n",
       "[3312 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = auto_mlf.predict(horizon)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9154b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e309f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_test, preds, on=[\"unique_id\", \"ds\"])\n",
    "daily_mase = partial(mase, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a809b0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoRidge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>47.814747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.685774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>0.727909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>66.339242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AutoRidge\n",
       "metric           \n",
       "mae     47.814747\n",
       "mape     0.685774\n",
       "mase     0.727909\n",
       "rmse    66.339242"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = evaluate(\n",
    "    df_eval, metrics=[mape, daily_mase, mae, rmse], train_df=df_train\n",
    ")\n",
    "error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ede7414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.51904029],\n",
       "       [0.07591187],\n",
       "       [0.09176441],\n",
       "       [4.41000725]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values\n",
    " - error_ref.drop(columns=[\"unique_id\"]).groupby(\"metric\").mean().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41a439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
